逻辑架构：
	大体来说，MySQL 可以分为 Server 层和存储引擎层两部分
	Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
	
	而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。
	
	连接器：连接器负责跟客户端建立连接、获取权限、维持和管理连接
		连接命令:mysql -h $ip -P $port -u $user -p 
		查看连接状态：show processlist
		长连接与短连接：
			连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个
			长连接的弊端：
				MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了
				解决：定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。
	查询缓存：
		mysql接受到查询请求后，会将查询sql作为key,查询结果作为value存储在缓存中，
		匹配key直接返回结果。
		更新表后，该表上的所有查询缓存将被清零。mysql8.0删除了查询缓存的功能
	分析器：
		对sql语句进行语法解析 You have an error in your SQL syntax
	优化器：
		在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。
	执行器：
		验证权限：在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限
			precheck无法校验存储过程、触发器等的权限，故运行时执行器需校验权限
		根据表的引擎，调用引擎接口
			如查询调用行取数据接口，一行一行累加
			rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。
			因此具体的说rows_examined字段可能与引擎扫描行数不等。
	上述为查询语句的执行流程，更新语句多了redolog和binlog

日志系统：
	redo_log物理日志：Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”
		wal:WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘
		当更新一条记录时，innodb引擎会先记录日志再更新内存，更新就完成了。之后在系统比较空闲的时候将操作日志记录到磁盘
		innodb的redo_log大小是固定的，有writepos和checkpoint记录当前记录位置和当前擦除位置，之间的部分就是可用空间大小
		当writepos追上checkpoint，此时不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下
		crash_safe:有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe
	bin_log逻辑日志(归档日志)：statement 格式的话是记sql语句，row格式会记录行的内容，记两条，更新前和更新后都有。
		redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
		redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
		redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
	innodb引擎更新语句流程：
		执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
		执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。
		然后告知执行器执行完成了，随时可以提交事务。执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
		执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。
	两阶段提交：redolog的prepare和commit状态
		redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。
		先写redolog后binlog:
			redolog写完数据库崩溃，此时binlog没有记录该操作，后续数据库重启，redolog生效。但是在备份数据库或数据库恢复某个时间点数据时，由于binlog缺少
			该更新操作，导致备份或恢复的数据库数据有问题
		先写binlog后redolog:
			binlog记录后没有记录redolog,redolog没有记录，数据库崩溃重启后，数据不会更新。而binlog已经记录更新，导致新库数据有问题。
	innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log都直接持久化到磁盘
	sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog都持久化到磁盘
	RTO（恢复目标时间）：这个指标依据全库备份的频率

事务隔离：
	Mysql的事务机制是引擎层面的。
	事务的ACID属性：Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性
	隔离级别：
		读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
		读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
		可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
		串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行
	查看数据库的隔离机制：show variables like 'transaction_isolation'
	隔离级别的实现：
		不同时段启动的事务会有不同的read-view,这样子相互之间的事务不会干扰,只会记录下每个事务对用的read-view的日志
		同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）
	长事务的弊端：
		长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。
		除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。
		查询长事务：		
			select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
		解决：
			首先，从应用开发端来看：
				确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。
				确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。
				业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）
			其次，从数据库端来看：
				监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；
				Percona 的 pt-kill 这个工具不错，推荐使用；
				在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；如果使用的是 MySQL  5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便
	事务的启动方式：
		显示开启：begin/start transaction,开启后不会自动提交 隐式开启：一条sql开启
		自动提交：set autocommit=1 关闭set autocommit=0
		避免长事务：采用autocommit=1 + 显示开启：begin
		commit work and chain：提交事务并开启新事务，避免多次begin交互的开销
		begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动，立即启动事务start transaction with consistent snapshot

索引：索引的出现其实就是为了提高数据查询的效率，就像书的目录一样
	提高读写效率的常见数据结构：
		哈希表：
			k-v存储数据结构：根据k算出一个确定的hash值，把v放到数组中对应的确定位置
			hash碰撞：多个k的hash值相等，解决：相等hash值的数组位置，用链表保存多个v，使用链表遍历查询
			因为哈希表的key换算的hash值不是有序的，做范围查询的时候需要全部扫描一遍，所以哈希表适用于等值查询的场景
		有序数组：
			有序数组在等值查询和范围查询场景中的性能就都非常优秀
			但是更新操作很慢，有序数组索引只适用于静态存储引擎
		二叉树：二叉搜索树的特点是：父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值
		N叉树：索引不止存在内存中，还要写到磁盘上。减少磁盘读写次数。
	在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。
	而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。
	Innodb索引模型：B+树
		每一个索引对应一个B+树
		索引组织表：表都是根据主键顺序以索引的形式存放
		主键索引的叶子节点存的是整行数据（Page）。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。
		非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）
		回表：基于非主键索引的查询需要多扫描一棵索引树
	索引维护:
		B+树的分裂与合并
		自增主键：NOT NULL PRIMARY KEY AUTO_INCREMENT,递增追加不会触发叶子结点的分裂
		主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小
		使用业务字段作为主键：
			只有一个索引；该索引必须是唯一索引。
	覆盖索引：索引覆盖查询需求，不需要在进行回表操作
		由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。
		建立冗余索引来支持覆盖索引时就需要权衡考虑(维护索引的代价，覆盖索引不需要回表操作)
	最左前缀原则：最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符
		联合索引的字段顺序设计：
			第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的
			其次考虑的原则就是空间
	索引下推：
		MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数

全局锁和表锁：mysql中的variables的设定只对改session有用，不是对全局的
	根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类
	全局锁：对整个数据库实例加锁。
		MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)
		阻塞数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句
		业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）
		全库逻辑备份：
			1.使用FTWRL弊端：
				如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆
				如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟
			2.官方工具 mysqldump：使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。
			不使用set global readonly=true原因：
				一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用
				二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高
	表级锁service层：MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。
		表锁的语法是 lock tables … read/write  unlock tables 主动释放锁，也可以在客户端断开的时候自动释放
		lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象(即本线程只能操作锁定表)
			影响太大，一般不用表锁来控制并发。
			写是排他锁，写锁意味着其他线程不能读也不能写。读锁是共享锁，加上后其他线程只能读不能写，本线程也不能写
				举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。
		MDL（metadata lock)
			在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁
			读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
			读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。
			事务的mdl锁在事务开始前获得，事务提交后释放。（这里有种特殊情况如果事务中包含DDL操作，mysql会在DDL操作语句执行前，隐式提交commit，以保证该DDL语句操作作为一个单独的事务存在，同时也保证元数据排他锁的释放）
				如：begin;alter table a add T int;select * from table a; 后面select不在前面事务中
			申请MDL锁的操作会形成一个队列，队列中写锁获取优先级高于读锁
		如何安全地给小表加字段：
			首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁
			alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。
				ALTER TABLE tbl_name NOWAIT add column ...
				ALTER TABLE tbl_name WAIT N add column ... 
行锁：引擎层
	两阶段锁：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议
	死锁和死锁检测：
		当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。
		解决：	
			设置超时时间：innodb_lock_wait_timeout 的默认值是 50s
			发起死锁检测：innodb_deadlock_detect 设置为on(默认)：发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行、
		死锁检测的性能问题：
			确保业务不会出现死锁，关闭死锁检测
			控制并发：客户端线程数
					  服务端修改mysql源码：思路：对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了
		    设计上：将一行改为逻辑上的多行数据，相当于增加了行级锁的个数
	建议：
	如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放
MVCC Multi-Version Concurrency Control:实现RC和RR
	一致性视图：
		begin/start transaction：一致性视图是在执行第一个快照读语句时创建的
		start transaction with consistent snapshot：一致性视图是在执行 start transaction with consistent snapshot 时创建的
	InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的
	每行数据有多个数据版本，每个数据版本有其更新时事务的id和旧数据版本的引用
	undolog:通过undolog计算出不同read_view
		当系统里没有比这个回滚日志更早的 read-view 的时候删除
	
	事务：
	每个事务启动瞬间，会有一个数组保存当前正在活跃(启动了未提交)的事务id
	数组里事务id的min记为低水位，当前系统创建过所有的事务Id的max+1记为高水位（start transaction with consistent snapshot开启事务，高水位为当前事务id）
	这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）
	对于当前事务的启动瞬间来说，一个数据版本的 row trx_id：
		小于低水位：表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；
		大于高水位：表示这个版本是由将来启动的事务生成的，是肯定不可见的
		低水位与高水位之间：
			a.  若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；自己的版本号可见
			b.  若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。
	
	即：
		版本未提交，不可见；
		版本已提交，但是是在视图创建后提交的，不可见；
		版本已提交，而且是在视图创建前提交的，可见
	更新逻辑：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）
			 除了 update 语句外，select 语句如果加锁，也是当前读。
				select k from t where id=1 lock in share mode; 读锁（共享锁）
				select k from t where id=1 for update; 写锁（排它锁）
	事务可重复读的实现：
		可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待
	提交读的区别：
		在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图
		在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图
	start transaction with consistent snapshot：创建一个持续整个事务的一致性快照，读可提交的隔离级别下与start transaction没区别
	
普通索引和唯一索引的选择：
	查询过程：性能几乎差不多。
		引擎是按也读取的，每张数据页的大小默认是16KB
		普通索引查询定位到数据后，需要查找下一个记录是否满足，唯一索引定位到数据可以直接返回。但是一个数据页保存近前个key，所以下一记录一般在同一数据页。
		所以普通索引定位到数据后向下一个记录查询消耗微乎其微。
	更新过程：
		change buffer : 当更新一个数据页时，如果该数据页在内存中，则直接更新。不在内存中，innodb将更新操作缓存在change buffer中，等到下次访问该数据页读取到内存是，根据执行change buffer中与数据页相关的操作。
		change buffer 在内存中有拷贝，也会写入磁盘
		merge:change buffer中的操作应用到数据页上。merge执行时期：访问数据页时、系统后台线程定期merge、数据库正常关闭shutdown
		merge 的执行流程：
			1.从磁盘读入数据页到内存（老版本的数据页）；
			2.从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；
			3.写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。
			数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了
		只有普通索引使用change buffer:
			对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。即需要读取数据页到内存，直接更新内存
		change buffer使用的是buffer pool中的内存，不能无限大。
			innodb_change_buffer_max_size：50 表示change buffer最大只能占用buffer pool 50%内存
		更新操作（插入）：
			1.数据页在内存中：性能差不多
				唯一索引，定位到索引位置后，判断是否冲突，插入
				普通索引：定位到索引位置后，直接插入
			2.数据页不在内存中：普通索引快
				唯一索引：读取数据页到内存，判断是否冲突，插入
				普通索引：将更新操作记录到change buffer中
	使用场景：
		因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。
		因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统
		反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。	
	索引选择和实践
		1.尽量选择普通索引。如果更新后涉及到马上读的操作，可以关闭change buffer(innodb_change_buffer_max_size:0)
		2.机械硬盘的库(IO较慢)：普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的
	change buffer和redo log:
		change buffer涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）change buffer的持久化
		redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。

Mysql选错索引：
	session A开启一致性快照事务，未提交时
	session B删除t表数据，调用存储过程重新新增数据，此时走索引查询，mysql可能会选错索引
	优化器的逻辑：
		优化器优化时会考虑的因素： 1.扫描行数（普通索引需要把回表开销计算代价） 2.是否使用临时表 3. 是否需要排序 综合代价最小
		扫描行数的判断：
			MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息(区分度)来估算记录数
			索引的区分度：显然，一个索引上不同的值（基数）越多，这个索引的区分度就越好。
			基数：一个索引上不同值的个数
		mysql的采样统计得到基数：
			InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数
			当数据表中变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计
			 MySQL 中，有两种存储索引统计的方式：innodb_stats_persistent 
			 on:统计信息会持久化存储：默认N=20 M=10
			 off:统计信息只会存储在内存中：默认N=8,M=16
		 analyse table t:重新统计索引信息（ explain 的结果预估的 rows 值跟实际情况差距比较大时使用）
	 索引选择异常和处理：
		1.强行选择一个索引:select * from t force index()
			可能问题：索引改名，语句也得改写、迁移数据库语法可能不兼容、最重要的是：变更的及时性-
			索引选择出错时少量情况下，所以再生产环境发现问题在使用后，又需要经过测试和发布
		2.我们可以考虑修改语句，引导 MySQL 使用我们期望的索引（不通用）
			order by b limit 1” 改成 “order by b,a limit 1” 语义逻辑相同
			但是优化器觉得使用索引b可以避免排序（索引本身排序），所以使用索引b
			而修改后，意味着使用这两个索引都需要排序。因此，扫描行数成了影响决策的主要条件，选择扫描行数少的索引a
			或者
			select * from  (select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1;
			增加索引b的代价
		3.我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。

前缀索引：有效减小索引文件的大小，提高索引的速度
	前缀索引后，可能会导致查询语句读数据的次数变多
	定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本
	定义长度：
		索引的区分度越高越好
		当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。
	前缀索引对覆盖索引的影响
		用前缀索引就用不上覆盖索引对查询性能的优化了
	等值查询条件下的前缀索引：
		索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低
		既可以占用更小的空间，也能达到相同的查询效率：
			第一种方式是使用倒序存储
			第二种方式是使用 hash 字段（表上新增字段）：由于可能产生hash冲突，所以hash后需要and精确条件
			区别：
				从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。
				在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。
				从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。
				
		故字符串字段建立索引时：
			直接创建完整索引，这样可能比较占用空间；
			创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
			倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
			创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

mysql数据库抖了一下：
	当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”
	平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）
	刷脏页的四种场景对性能的影响：
		第一种是“redo log 写满了，要 flush 脏页”
			整个系统就不能再接受更新了，所有的更新都必须堵住，这种情况应该尽量避免
		第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态
			InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态
				第一种是，还没有使用的；第二种是，使用了并且是干净页；第三种是，使用了并且是脏页
			InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。
			而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用
			所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的
				一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；
				日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的
	InnoDB 刷脏页的控制策略
		 innodb_io_capacity:正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快
		 影响刷脏页的速度的因素：
			脏页比例 innodb_max_dirty_pages_pct 默认75%
				根据当前脏页Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 比例M计算出一个0-100的数：f(M)
			redo log写盘速度
				InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N
				InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字:f(N)
		根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度
		刷脏页的邻居策略：innodb_flush_neighbors
			0：自刷自己的脏页 1：顺带刷脏页旁边的数据页 
			ssd下，因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间
			在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了
		io能力强，redo设置过小会出现：磁盘压力很小，但是数据库出现间歇性的性能下跌。

表数据删掉一般，表文件大小不变？
	一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。
	参数 innodb_file_per_table：表数据既可以存在共享表空间里，也可以是单独的文件
		off:表的数据放在系统共享表空间information_schema，也就是跟数据字典放在一起；
		on:每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件
		从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了.因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。
	数据删除流程：
		 InnoDB 的数据是按页存储，删除记录，只会被标记为可复用。但是磁盘上，文件不会变小
		 数据页的复用跟记录的复用是不同的：
			记录的复用，只限于符合范围条件的数据，而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置
		 这些可以复用，而没有被使用的空间，看起来就像是“空洞”
		 插入数据也会：如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂
		 更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的
		 过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的（重建表）
	 重建表：
		新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中
		alter table A engine=InnoDB 命令来重建表：
			MySQL 5.5 版本之前，MySQL 会自动完成转存数据、交换表名、删除旧表的操作，ddl过程中，A的更新操作会丢失
			MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化
					建立一个临时文件，扫描表 A 主键的所有数据页；
					用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；
					生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，；
					临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，；
					用临时文件替换表 A 的数据文件。
			写锁退化：alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了
			那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做 DDL
				为什么要退化呢？为了实现 Online，MDL 读锁不会阻塞增删改操作
		上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用 GitHub 开源的 gh-ost 来做
	Online 和 inplace
		使用临时表是在service层，而使用临时文件是innodb内部的，对于service层是无感的，就像一个原地inplace的操作
		alter table t engine=innodb的实际命令是：alter table t engine=innodb,ALGORITHM=inplace;
		如果使用alter table t engine=innodb,ALGORITHM=copy 就会copy临时表
		DDL 过程如果是 Online 的，就一定是 inplace 的；
		反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况
	optimize table、analyze table 和 alter table
		从 MySQL 5.6 版本开始，alter table t engine = InnoDB（也就是 recreate）默认的inplace流程了；
		analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；
		optimize table t 等于 recreate+analyze。
	表重建后，表空间更大：原.idb文件中数据页很少空洞页，此时重建时，有dml操作执行引入了一些新的空洞
	第二种可能：在重建表的时候，InnoDB 不会把整张表占满，每个页留了 1/16 给后续的更新用。也就是说，其实重建表之后不是“最”紧凑的。
		如果将t表重建，后续dml操作使用了预留空间，再次重建t表，t表的数据文件肯定增大

count(*)慢？
	MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；
	而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数
		由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的
	InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之
	show table status 显示的行数时基于采样估算来的，不准确
	
	解决：
		用缓存系统保存计数
			将计数保存在缓存系统中(如redis)的方式，还不只是丢失更新(redis故障)的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的(数据库的增删操作与redis的技术操作不是事务，这样操作就有时许问题)
		在数据库保存计数（新建表）
			解决系统崩溃问题：redo log ,解决时序问题：事务
	不同的count:
		性能分析的原则：
			server 层要什么就给什么；
			nnoDB 只给必要的值；
			现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做。
		count(字段)：字段定义不为null,按行读取字段，判断不能为null+1
		count(id):InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加
		count(1):InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加
		count(*):并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。
		
日志和索引相关问题：
	两阶段提交：
		binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理：
			如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交
			如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：
				a.  如果是，则提交事务；b.  否则，回滚事务
		binlog的完整：
			一个事务的 binlog 是有完整格式的：
				statement 格式的 binlog，最后会有 COMMIT；row 格式的 binlog，最后会有一个 XID event
			另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。
			对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。
		redo log 和 binlog 是怎么关联起来的：
			它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log
				如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
				如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务
		处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计
			在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用
			所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性
		如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑
			对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了
			两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交
		不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了
			历史原因： InnoDB 并不是 MySQL 的原生存储引擎。MySQL 的原生引擎是 MyISAM，设计之初就有没有支持崩溃恢复
			实现原因：binlog 没有能力恢复“数据页”：两个事物提交了，b事物提交前crash，a事物无法应用binlog判断
		那能不能反过来，只用 redo log，不要 binlog
			一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用
			总之，由于现在包括 MySQL 高可用在内的很多系统机制都依赖于 binlog，所以“鸠占鹊巢”redo log 还做不到。你看，发展生态是多么重要
		正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢
			实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况
			如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系
			崩溃/恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态
		redo log buffer 是什么？是先修改内存，还是先写 redo log 文件
			redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志
			但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的

order by 是怎么工作的？
	Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer
	例子：
		select city,name,age from t where city='杭州' order by name limit 1000  ;
		全字段排序：
			初始化 sort_buffer，确定放入 name、city、age 这三个字段；
			从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；
			到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；
			从索引 city 取下一个记录的主键 id；
			重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；
			对 sort_buffer 中的数据按照字段 name 做快速排序；按照排序结果取前 1000 行返回给客户端
		sort_buffer_size:MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序
			每个磁盘文件采用归并算法排序：读取一个文件到sort_buffer，排序，读取下一文件到sort_buffer排序。这样每个磁盘文件是排序了的。
			再将有序的小文件合成有序的大文件
		判断是否使用临时文件：			
			/* 打开optimizer_trace，只对本线程有效 */
			SET optimizer_trace='enabled=on'; 
			
			/* @a保存Innodb_rows_read的初始值 */
			select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';
			
			/* 执行语句 */
			select city, name,age from t where city='杭州' order by name limit 1000; 
			
			/* 查看 OPTIMIZER_TRACE 输出 */
			SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G
			
			/* @b保存Innodb_rows_read的当前值 */
			select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';
			
			/* 计算Innodb_rows_read差值 */
			select @b-@a;
			optimizer_trace中：
				number_of_tmp_files 表示临时文件的数量，当然sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大
				sort_mode 里面的 packed_additional_fields :排序过程对字符串做了“紧凑”处理。即使 name 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的
			 internal_tmp_disk_storage_engine :设置临时表存储引擎 默认innodb
				 MyISAM：扫描4000行
				 InnoDB：扫描4001行：读取OPTIMIZER_TRACE 这个表时，需要用到临时表，innodb引擎会+1
	 rowid 排序：
		max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法
		新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id
		rowid 排序多访问了一次表 t 的主键索引
	全字段排序 VS rowid 排序:
		如果内存够，就要多利用内存，尽量减少磁盘访问。全字段排序
	order by 不一定排序
		从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的
		建立查询条件字段与排序字段的联合索引：不用排序
		建立查询字段和排序字段的覆盖索引：不用排序和回表
		